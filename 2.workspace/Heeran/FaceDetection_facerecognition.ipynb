{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceDetection_facerecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQer1-YjNVoi"
      },
      "source": [
        "pip install face-recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRY3oMhVNXug"
      },
      "source": [
        "%pylab inline \r\n",
        "import face_recognition\r\n",
        "import cv2\r\n",
        "import matplotlib.patches as patches\r\n",
        "from IPython.display import clear_output\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import matplotlib.pylab as plt\r\n",
        "import cv2\r\n",
        "import matplotlib.patches as patches\r\n",
        "from IPython.display import clear_output\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import matplotlib.pylab as plt\r\n",
        "\r\n",
        "\r\n",
        "# Loading video for face detection\r\n",
        "video_capture = cv2.VideoCapture(\"/content/gdrive/MyDrive/Colab Notebooks/딥러닝data/fastandfurious_short.mov\")\r\n",
        "\r\n",
        "frame_count = 0\r\n",
        "\r\n",
        "while video_capture.isOpened():    \r\n",
        "    # Grab a single frame of video\r\n",
        "    ret, frame = video_capture.read()\r\n",
        "\r\n",
        "    # Bail out when the video file ends\r\n",
        "    if not ret:\r\n",
        "        video_capture.release()\r\n",
        "        break\r\n",
        "        \r\n",
        "    # We will search face in every 15 frames to speed up process.\r\n",
        "    frame_count += 1\r\n",
        "    if frame_count % 15 == 0:    \r\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
        "        \r\n",
        "        # Display video frame\r\n",
        "        title(\"Input Stream\")\r\n",
        "        plt.imshow(frame)        \r\n",
        "\r\n",
        "        # Find all the faces and face encodings in the current frame of video\r\n",
        "        rgb_frame = frame[:, :, ::-1]\r\n",
        "        face_locations = face_recognition.face_locations(rgb_frame)\r\n",
        "        \r\n",
        "        # If faces were found, we will mark it on frame with blue dots\r\n",
        "        for face_location in face_locations:        \r\n",
        "            plt.plot(face_location[1], face_location[0], 'bo')\r\n",
        "            plt.plot(face_location[1], face_location[2], 'bo')\r\n",
        "            plt.plot(face_location[3], face_location[2], 'bo')\r\n",
        "            plt.plot(face_location[3], face_location[0], 'bo')\r\n",
        "\r\n",
        "        # Show frame...\r\n",
        "        plt.show() \r\n",
        "        # ... and hold it until a new frame appears\r\n",
        "        clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}